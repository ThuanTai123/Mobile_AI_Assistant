import { useState, useEffect, useRef } from 'react';
import { Platform, Alert } from 'react-native';
import Voice, { 
  SpeechRecognizedEvent, 
  SpeechResultsEvent, 
  SpeechErrorEvent,
  SpeechStartEvent,
  SpeechEndEvent 
} from '@react-native-voice/voice';

interface VoiceError {
  code?: string;
  message?: string;
}

interface UseVoiceReturn {
  isListening: boolean;
  results: string[];
  partialTranscript: string;
  error: string | null;
  startListening: () => Promise<void>;
  stopListening: () => Promise<void>;
  cancelListening: () => Promise<void>;
  destroyRecognizer: () => Promise<void>;
}

const useVoice = (): UseVoiceReturn => {
  const [isListening, setIsListening] = useState(false);
  const [results, setResults] = useState<string[]>([]);
  const [partialTranscript, setPartialTranscript] = useState('');
  const [error, setError] = useState<string | null>(null);
  const timeoutRef = useRef<NodeJS.Timeout | null>(null);
  const isListeningRef = useRef(false);

  useEffect(() => {
    Voice.onSpeechStart = onSpeechStart;
    Voice.onSpeechRecognized = onSpeechRecognized;
    Voice.onSpeechEnd = onSpeechEnd;
    Voice.onSpeechError = onSpeechError;
    Voice.onSpeechResults = onSpeechResults;
    Voice.onSpeechPartialResults = onSpeechPartialResults;
    Voice.onSpeechVolumeChanged = onSpeechVolumeChanged;

    return () => {
      Voice.removeAllListeners();
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
      }
    };
  }, []);

  const onSpeechStart = (e: SpeechStartEvent) => {
    console.log('üé§ Speech recognition started', e);
    setIsListening(true);
    setError(null);
  };

  const onSpeechRecognized = (e: SpeechRecognizedEvent) => {
    console.log('üéØ Speech recognized', e);
  };

  const onSpeechEnd = (e: SpeechEndEvent) => {
    console.log('üõë Speech recognition ended', e);
    setIsListening(false);
    setPartialTranscript('');
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current);
      timeoutRef.current = null;
    }
  };

  const onSpeechError = (e: SpeechErrorEvent) => {
    console.error('‚ùå Speech recognition error', e);
    const errorCode = e.error?.code?.toString() || '';
    const errorMessage = e.error?.message || 'L·ªói nh·∫≠n d·∫°ng gi·ªçng n√≥i';

    setError(errorMessage);
    setIsListening(false);
    setPartialTranscript('');

    if (errorCode !== '7') {
      Alert.alert(
        'L·ªói nh·∫≠n d·∫°ng gi·ªçng n√≥i',
        getErrorMessage(errorCode),
        [{ text: 'OK' }]
      );
    }
  };

  const onSpeechResults = (e: SpeechResultsEvent) => {
    console.log('üìù Speech results', e);
    if (e.value && e.value.length > 0) {
      setResults(e.value);
      setPartialTranscript('');
      setIsListening(false);
      isListeningRef.current = false;
    }
  };

  const onSpeechPartialResults = (e: SpeechResultsEvent) => {
    console.log('üìù Partial results', e);
    if (e.value && e.value.length > 0) {
      setPartialTranscript(e.value[0]);
    }
  };

  const onSpeechVolumeChanged = (_: any) => {
    // Volume indicator placeholder
  };

  const getErrorMessage = (errorCode: string): string => {
    const errorMessages: { [key: string]: string } = {
      '1': 'L·ªói m·∫°ng. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet.',
      '2': 'L·ªói √¢m thanh. Vui l√≤ng ki·ªÉm tra microphone.',
      '3': 'L·ªói m√°y ch·ªß. Vui l√≤ng th·ª≠ l·∫°i sau.',
      '4': 'Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p microphone.',
      '5': 'D·ªãch v·ª• nh·∫≠n d·∫°ng gi·ªçng n√≥i kh√¥ng kh·∫£ d·ª•ng.',
      '6': 'Kh√¥ng ƒë·ªß b·ªô nh·ªõ.',
      '7': 'Kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c gi·ªçng n√≥i. Vui l√≤ng n√≥i r√µ h∆°n.',
      '8': 'D·ªãch v·ª• b·∫≠n. Vui l√≤ng th·ª≠ l·∫°i.',
      '9': 'D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ nh·∫≠n d·∫°ng.',
    };
    return errorMessages[errorCode] || 'ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh.';
  };

  const startListening = async (): Promise<void> => {
    if (isListeningRef.current) {
      console.log('üéß ƒê√£ ƒëang nghe, kh√¥ng g·ªçi l·∫°i');
      return;
    }

    try {
      setError(null);
      setResults([]);
      setPartialTranscript('');
      setIsListening(true);
      isListeningRef.current = true;
      // ‚ö†Ô∏è H·ªßy tr∆∞·ªõc ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng ch·ªìng l·ªánh
      try {
        await Voice.cancel();
        await new Promise(resolve => setTimeout(resolve, 300)); // delay ng·∫Øn
      } catch (cancelErr) {
        console.warn('‚ö†Ô∏è Voice.cancel() error (kh√¥ng nghi√™m tr·ªçng)', cancelErr);
      }

      console.log('üéôÔ∏è B·∫Øt ƒë·∫ßu nh·∫≠n d·∫°ng gi·ªçng n√≥i...');
      await Voice.start('vi-VN'); // ‚ùó Kh√¥ng g·ªçi setIsListening(true) ·ªü ƒë√¢y

      // ƒê·∫∑t timeout auto stop sau 10s
      timeoutRef.current = setTimeout(async () => {
        if (isListening) {
          console.log('‚è∞ Auto stopping voice recognition after timeout');
          await stopListening();
        }
      }, 10000);
    } catch (err) {
      console.error('‚ùå L·ªói khi b·∫Øt ƒë·∫ßu nh·∫≠n d·∫°ng gi·ªçng n√≥i:', err);
      setIsListening(false);
      setError('Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n d·∫°ng gi·ªçng n√≥i. Vui l√≤ng ki·ªÉm tra microphone.');
      Alert.alert('L·ªói', 'Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n d·∫°ng gi·ªçng n√≥i. Vui l√≤ng ki·ªÉm tra quy·ªÅn microphone.', [{ text: 'OK' }]);
    }
  };

  const stopListening = async (): Promise<void> => {
    try {
      console.log('üõë D·ª´ng nh·∫≠n d·∫°ng');
      setIsListening(false);

      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
        timeoutRef.current = null;
      }

      await new Promise(resolve => setTimeout(resolve, 300)); // Delay tr√°nh l·ªói
      await Voice.cancel(); // D·ª´ng t·∫•t c·∫£ m·ªçi th·ª©
    } catch (err) {
      console.error('‚ùå L·ªói khi d·ª´ng nh·∫≠n d·∫°ng:', err);
    }
  };

  const cancelListening = async (): Promise<void> => {
    try {
      console.log('‚ùå H·ªßy nh·∫≠n d·∫°ng');
      setIsListening(false);
      setPartialTranscript('');
      setResults([]);

      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
        timeoutRef.current = null;
      }

      await new Promise(resolve => setTimeout(resolve, 300));
      await Voice.cancel();
    } catch (err) {
      console.error('‚ùå L·ªói khi h·ªßy nh·∫≠n d·∫°ng:', err);
    }
  };

  const destroyRecognizer = async (): Promise<void> => {
    try {
      console.log('üóëÔ∏è H·ªßy ho√†n to√†n voice recognizer');
      setIsListening(false);
      setPartialTranscript('');
      setResults([]);
      setError(null);

      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
        timeoutRef.current = null;
      }

      await Voice.destroy();
    } catch (err) {
      console.error('‚ùå L·ªói khi h·ªßy Voice.destroy()', err);
    }
  };

  return {
    isListening,
    results,
    partialTranscript,
    error,
    startListening,
    stopListening,
    cancelListening,
    destroyRecognizer,
  };
};


export default useVoice;