import { useState, useEffect, useRef, useCallback } from 'react';
import { Platform, Alert, PermissionsAndroid } from 'react-native';
import Voice, { 
  SpeechRecognizedEvent, 
  SpeechResultsEvent, 
  SpeechErrorEvent,
  SpeechStartEvent,
  SpeechEndEvent 
} from '@react-native-voice/voice';

interface UseVoiceReturn {
  isListening: boolean;
  results: string[];
  partialTranscript: string;
  error: string | null;
  startListening: () => Promise<void>;
  stopListening: () => Promise<void>;
  cancelListening: () => Promise<void>;
  destroyRecognizer: () => Promise<void>;
}

const useVoice = (): UseVoiceReturn => {
  const [isListening, setIsListening] = useState(false);
  const [results, setResults] = useState<string[]>([]);
  const [partialTranscript, setPartialTranscript] = useState('');
  const [error, setError] = useState<string | null>(null);
  const timeoutRef = useRef<NodeJS.Timeout | null>(null);
  const isOperatingRef = useRef(false);
  const mountedRef = useRef(true);
  const sessionActiveRef = useRef(false);

  useEffect(() => {
    mountedRef.current = true;
    return () => {
      mountedRef.current = false;
      cleanupVoice();
    };
  }, []);

  const safeSetState = useCallback((updater: () => void) => {
    if (mountedRef.current) {
      updater();
    }
  }, []);

  // Cleanup ho√†n to√†n Voice service
  const cleanupVoice = async () => {
    try {
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
        timeoutRef.current = null;
      }
      
      Voice.removeAllListeners();
      await Voice.cancel();
      await Voice.stop();
      await Voice.destroy();
      await new Promise(resolve => setTimeout(resolve, 300));
      
      sessionActiveRef.current = false;
      console.log('üßπ Voice cleanup completed');
    } catch (err) {
      // Kh√¥ng log cleanup errors
    }
  };

  // Setup Voice service t·ª´ ƒë·∫ßu
  const setupVoice = async () => {
    try {
      // Cleanup tr∆∞·ªõc
      await cleanupVoice();
      
      // Setup listeners m·ªõi
      Voice.onSpeechStart = (e: SpeechStartEvent) => {
        console.log('üé§ Speech recognition started', e);
        sessionActiveRef.current = true;
        safeSetState(() => {
          setIsListening(true);
          setError(null);
        });
      };

      Voice.onSpeechEnd = (e: SpeechEndEvent) => {
        console.log('üõë Speech recognition ended', e);
        sessionActiveRef.current = false;
        safeSetState(() => {
          setIsListening(false);
          setPartialTranscript('');
        });
        
        if (timeoutRef.current) {
          clearTimeout(timeoutRef.current);
          timeoutRef.current = null;
        }
      };

      Voice.onSpeechError = (e: SpeechErrorEvent) => {
        const errorCode = e.error?.code?.toString() || '';
        
        // Ch·ªâ log c√°c l·ªói nghi√™m tr·ªçng, b·ªè qua error code 5, 7, 11
        if (!['5', '7', '11'].includes(errorCode)) {
          console.error('‚ùå Speech recognition error', e);
        }
        
        sessionActiveRef.current = false;
        safeSetState(() => {
          setIsListening(false);
          setPartialTranscript('');
        });
        
        if (timeoutRef.current) {
          clearTimeout(timeoutRef.current);
          timeoutRef.current = null;
        }
        
        // Ignore common errors
        if (['5', '7', '11'].includes(errorCode)) {
          return;
        }
        
        const errorMessage = getErrorMessage(errorCode);
        safeSetState(() => setError(errorMessage));
      };

      Voice.onSpeechResults = (e: SpeechResultsEvent) => {
        console.log('üìù Speech results', e);
        if (e.value && e.value.length > 0) {
          console.log('üì§ Voice result received:', e.value[0]);
          sessionActiveRef.current = false;
          safeSetState(() => {
            setResults(e.value || []);
            setPartialTranscript('');
            setIsListening(false);
          });
          
          // Cleanup ngay sau khi c√≥ k·∫øt qu·∫£
          setTimeout(cleanupVoice, 500);
        }
      };

      Voice.onSpeechPartialResults = (e: SpeechResultsEvent) => {
        if (e.value && e.value.length > 0) {
          safeSetState(() => setPartialTranscript(e.value?.[0] || ''));
        }
      };

      Voice.onSpeechRecognized = () => {
        console.log('üéØ Speech recognized');
      };

      Voice.onSpeechVolumeChanged = () => {};

      console.log('‚úÖ Voice service setup completed');
    } catch (err) {
      console.error('‚ùå Voice setup error:', err);
      throw err;
    }
  };

  const getErrorMessage = (errorCode: string): string => {
    const errorMessages: { [key: string]: string } = {
      '1': 'L·ªói m·∫°ng. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet.',
      '2': 'L·ªói √¢m thanh. Vui l√≤ng ki·ªÉm tra microphone.',
      '3': 'L·ªói m√°y ch·ªß. Vui l√≤ng th·ª≠ l·∫°i sau.',
      '4': 'Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p microphone.',
      '6': 'Kh√¥ng ƒë·ªß b·ªô nh·ªõ.',
      '8': 'D·ªãch v·ª• b·∫≠n. Vui l√≤ng th·ª≠ l·∫°i.',
      '9': 'D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ nh·∫≠n d·∫°ng.',
    };
    return errorMessages[errorCode] || 'ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh.';
  };

  const checkPermission = async (): Promise<boolean> => {
    if (Platform.OS === 'android') {
      try {
        const granted = await PermissionsAndroid.check(
          PermissionsAndroid.PERMISSIONS.RECORD_AUDIO
        );
        
        if (!granted) {
          const result = await PermissionsAndroid.request(
            PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
            {
              title: 'Quy·ªÅn truy c·∫≠p Microphone',
              message: '·ª®ng d·ª•ng c·∫ßn quy·ªÅn truy c·∫≠p microphone ƒë·ªÉ nh·∫≠n d·∫°ng gi·ªçng n√≥i',
              buttonNeutral: 'H·ªèi l·∫°i sau',
              buttonNegative: 'H·ªßy',
              buttonPositive: 'ƒê·ªìng √Ω',
            }
          );
          return result === PermissionsAndroid.RESULTS.GRANTED;
        }
        return true;
      } catch (err) {
        console.error('Permission check error:', err);
        return false;
      }
    }
    return true;
  };

  const startListening = useCallback(async (): Promise<void> => {
    if (isOperatingRef.current || sessionActiveRef.current) {
      console.log('üéß Already operating, ignoring');
      return;
    }

    try {
      isOperatingRef.current = true;
      
      // Check permission
      const hasPermission = await checkPermission();
      if (!hasPermission) {
        Alert.alert('L·ªói', 'C·∫ßn quy·ªÅn truy c·∫≠p microphone');
        return;
      }

      // Setup Voice service t·ª´ ƒë·∫ßu
      await setupVoice();

      // Reset states
      safeSetState(() => {
        setError(null);
        setResults([]);
        setPartialTranscript('');
      });

      console.log('üéôÔ∏è B·∫Øt ƒë·∫ßu nh·∫≠n d·∫°ng gi·ªçng n√≥i...');
      
      // Start recognition
      await Voice.start('vi-VN');

      // Set timeout
      timeoutRef.current = setTimeout(async () => {
        if (sessionActiveRef.current) {
          console.log('‚è∞ Auto stopping after timeout');
          await stopListening();
        }
      }, 8000);

    } catch (err) {
      console.error('‚ùå Start listening error:', err);
      safeSetState(() => {
        setError('Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n d·∫°ng gi·ªçng n√≥i');
        setIsListening(false);
      });
      sessionActiveRef.current = false;
    } finally {
      isOperatingRef.current = false;
    }
  }, [safeSetState]);

  const stopListening = useCallback(async (): Promise<void> => {
    if (isOperatingRef.current) {
      return;
    }

    try {
      isOperatingRef.current = true;
      console.log('üõë D·ª´ng nh·∫≠n d·∫°ng');
      
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
        timeoutRef.current = null;
      }

      await Voice.stop();
      
      // Cleanup sau khi stop
      setTimeout(async () => {
        await cleanupVoice();
        safeSetState(() => setIsListening(false));
      }, 500);
      
    } catch (err) {
      // Kh√¥ng log stop errors
    } finally {
      sessionActiveRef.current = false;
      isOperatingRef.current = false;
    }
  }, [safeSetState]);

  const cancelListening = useCallback(async (): Promise<void> => {
    try {
      console.log('‚ùå H·ªßy nh·∫≠n d·∫°ng');
      
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current);
        timeoutRef.current = null;
      }

      await cleanupVoice();
      
      safeSetState(() => {
        setIsListening(false);
        setPartialTranscript('');
        setResults([]);
      });
      
    } catch (err) {
      // Kh√¥ng log cancel errors
    } finally {
      sessionActiveRef.current = false;
      isOperatingRef.current = false;
    }
  }, [safeSetState]);

  const destroyRecognizer = useCallback(async (): Promise<void> => {
    try {
      console.log('üóëÔ∏è Destroying voice recognizer');
      
      await cleanupVoice();
      
      safeSetState(() => {
        setIsListening(false);
        setPartialTranscript('');
        setResults([]);
        setError(null);
      });
      
    } catch (err) {
      // Kh√¥ng log destroy errors
    } finally {
      sessionActiveRef.current = false;
      isOperatingRef.current = false;
    }
  }, [safeSetState]);

  return {
    isListening,
    results,
    partialTranscript,
    error,
    startListening,
    stopListening,
    cancelListening,
    destroyRecognizer,
  };
};

export default useVoice;